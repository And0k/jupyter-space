{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/And0k/jupyter-space/blob/main/%D0%9A%D0%BE%D1%80%D0%B6_%D0%90_%D0%9C%D0%98%D0%98_%D0%A0%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D1%81%D1%8A%D0%B5%D0%B4%D0%BE%D0%B1%D0%BD%D1%8B%D1%85_%D0%B4%D0%B8%D0%BA%D0%BE%D1%80%D0%B0%D1%81%D1%82%D1%83%D1%89%D0%B8%D1%85_%D1%80%D0%B0%D1%81%D1%82%D0%B5%D0%BD%D0%B8%D0%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jEkbZZ06wFNX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px  # Library that generates interactive web-based visualizations."
      ],
      "metadata": {
        "id": "dIS3m5KIafVz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf4-2g-ojuuv",
        "outputId": "e94d8e27-0fbf-45f9-c7a7-3721312782dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset and metadata file names and paths\n",
        "dataset_name = \"gverzea/edible-wild-plants\"\n",
        "metadata_file = \"edible wild plants metadata.xls\"\n",
        "my_drive_dest = \"drive/My Drive/Colab Notebooks/Методы ИИ\"\n",
        "\n",
        "# Extract dataset stem from dataset name\n",
        "dataset_stem = dataset_name.split('/', 1)[-1]\n",
        "dataset_path = rf'{my_drive_dest}/{dataset_stem}'"
      ],
      "metadata": {
        "id": "fooj_BBQPbTK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка датасета с Kaggle и копирование на Google Диск (при первом запуске)\n",
        "(you'll need press button to select and upload kaggle.json from you local computer if interaction with Kaggle will be needed)"
      ],
      "metadata": {
        "id": "3ymMYZPw7ha8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if metadata file exists, if not, download and extract dataset\n",
        "metadata_path = f'{dataset_path}/{metadata_file}'\n",
        "if not os.path.exists(metadata_path):\n",
        "    dataset_zip = f\"{dataset_stem}.zip\"  # file name that appears to be downloaded after downloading dataset\n",
        "    dataset_zip_path = rf'{my_drive_dest}/{dataset_zip}'\n",
        "    if not os.path.exists(dataset_zip_path):\n",
        "        my_drive_dest_for_cmd = my_drive_dest.replace(' ', '\\ ')\n",
        "\n",
        "        # Kaggle access file (from my_drive_dest or upload)\n",
        "        if not os.path.exists(os.path.expanduser('~/.kaggle/kaggle.json')):\n",
        "            !mkdir ~/.kaggle\n",
        "            if os.path.exists(rf'{my_drive_dest}/kaggle.json'):\n",
        "                !cp $my_drive_dest_for_cmd/kaggle.json ~/.kaggle/\n",
        "            else:\n",
        "                print(\"Select kaggle.json to dounload to Google Colab\")\n",
        "                from google.colab import files\n",
        "                uploaded = files.upload()\n",
        "                !cp kaggle.json ~/.kaggle/\n",
        "            !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "        # Dataset zip file (autoskipping if exist)\n",
        "        !kaggle datasets download $dataset_name -p $my_drive_dest_for_cmd\n",
        "\n",
        "    import zipfile\n",
        "\n",
        "    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(dataset_path)\n",
        "\n",
        "# # Directory to extract the contents\n",
        "# extract_path = 'dataset_folder'\n",
        "\n",
        "# # Create the extraction directory if it doesn't exist\n",
        "# os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# # Extract the zip file\n",
        "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "AR5NVO1PtqMo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Просмотр состава данных"
      ],
      "metadata": {
        "id": "9s1g_yUt_rK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load metadata from Excel file\n",
        "df_in = pd.read_excel(metadata_path)\n",
        "df_in.set_index(\"Name\", inplace=True)\n",
        "print(df_in['# pics'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXufqegmf4o7",
        "outputId": "3c13a8a8-44e7-4021-9fbb-d6b7195ff512"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name\n",
            "Alfalfa                50\n",
            "Asparagus             100\n",
            "Blue Vervain           50\n",
            "Broadleaf Plantain     50\n",
            "Bull Thistle           50\n",
            "                     ... \n",
            "Wild Bee Balm          50\n",
            "Wild Black Cherry      50\n",
            "Wild Grape Vine       100\n",
            "Wild Leek             100\n",
            "Wood Sorrel            50\n",
            "Name: # pics, Length: 62, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание класса Custom Dataset в PyTorch"
      ],
      "metadata": {
        "id": "custom-dataset-class"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the device to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7smZArVj54-p",
        "outputId": "ed9f2096-2589-4056-f95e-30c35ec1c8d2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверка наличия изображений данных в ожидаемых директориях и отображение сетки изображений"
      ],
      "metadata": {
        "id": "weGrTFiMQy3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Check if images are available in the expected directories\n",
        "def check_images_availability(dataset_path):\n",
        "    subfolders = ['dataset', 'dataset-test', 'dataset-user_images']\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_path = os.path.join(dataset_path, subfolder)\n",
        "        if not os.path.exists(subfolder_path):\n",
        "            print(f\"Directory {subfolder_path} does not exist.\")\n",
        "            return False\n",
        "        if not os.listdir(subfolder_path):\n",
        "            print(f\"Directory {subfolder_path} is empty.\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Draw a grid of one image for each class\n",
        "def draw_image_grid(dataset_path):\n",
        "    classes = os.listdir(os.path.join(dataset_path, 'dataset'))\n",
        "    num_classes = len(classes)\n",
        "    fig, axes = plt.subplots(1, num_classes, figsize=(20, 20))\n",
        "    for i, cls in enumerate(classes):\n",
        "        class_path = os.path.join(dataset_path, 'dataset', cls)\n",
        "        image_file = random.choice(os.listdir(class_path))\n",
        "        image_path = os.path.join(class_path, image_file)\n",
        "        image = Image.open(image_path)\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(cls)\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Check images availability and draw grid\n",
        "if check_images_availability(dataset_path):\n",
        "    draw_image_grid(dataset_path)\n",
        "else:\n",
        "    print(\"Images are not available in the expected directories.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kan5_xi9Qxxw",
        "outputId": "0457a38f-be42-417e-f547-e0fab2ed39e4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory drive/My Drive/Colab Notebooks/Методы ИИ/edible-wild-plants/dataset does not exist.\n",
            "Images are not available in the expected directories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class EdibleWildPlantsDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = glob.glob(f'{root_dir}/**/*.jpg', recursive=True)\n",
        "        self.labels = [path.split('/')[-2] for path in self.image_paths]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "custom-dataset-class-code"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Предобработка изображений"
      ],
      "metadata": {
        "id": "image-preprocessing"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import v2\n",
        "\n",
        "# Define the data transformations\n",
        "data_transforms = v2.Compose([\n",
        "    v2.RandomResizedCrop(size=(224, 224), antialias=True),  # Randomly crop and resize images to 224x224 pixels with antialiasing\n",
        "    v2.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    v2.RandomRotation(10),  # Randomly rotate images by 10 degrees\n",
        "    v2.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images with mean and std\n",
        "])"
      ],
      "metadata": {
        "id": "image-preprocessing-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Разделение датасета на обучающую и тестовую выборки"
      ],
      "metadata": {
        "id": "dataset-splitting"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "dataset = EdibleWildPlantsDataset(root_dir=dataset_path, transform=data_transforms)\n",
        "train_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)"
      ],
      "metadata": {
        "id": "dataset-splitting-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Примеры распознавания из папки dataset-user_images"
      ],
      "metadata": {
        "id": "recognition-examples"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and display examples from user images dataset\n",
        "user_images_dataset = EdibleWildPlantsDataset(root_dir=f'{dataset_path}/dataset-user_images', transform=data_transforms)\n",
        "\n",
        "for i in range(5):\n",
        "    image, label = user_images_dataset[i]\n",
        "    plt.imshow(image.permute(1, 2, 0))\n",
        "    plt.title(label)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "recognition-examples-code"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
