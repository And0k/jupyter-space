{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/And0k/jupyter-space/blob/main/%D0%9A%D0%BE%D1%80%D0%B6_%D0%90_%D0%9C%D0%98%D0%98_%D0%A0%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D1%81%D1%8A%D0%B5%D0%B4%D0%BE%D0%B1%D0%BD%D1%8B%D1%85_%D0%B4%D0%B8%D0%BA%D0%BE%D1%80%D0%B0%D1%81%D1%82%D1%83%D1%89%D0%B8%D1%85_%D1%80%D0%B0%D1%81%D1%82%D0%B5%D0%BD%D0%B8%D0%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jEkbZZ06wFNX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px  # Library that generates interactive web-based visualizations."
      ],
      "metadata": {
        "id": "dIS3m5KIafVz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf4-2g-ojuuv",
        "outputId": "89fc9443-a6d6-497b-c489-63f3fc23be8c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset and metadata file names and paths\n",
        "dataset_package_name = \"gverzea/edible-wild-plants\"\n",
        "metadata_file = \"edible wild plants metadata.xls\"\n",
        "my_drive_dest = \"drive/My Drive/Colab Notebooks/Методы ИИ\"\n",
        "\n",
        "# Extract dataset stem from dataset name\n",
        "dataset_package_stem = dataset_package_name.split('/', 1)[-1]\n",
        "dataset_package_path = rf'{my_drive_dest}/{dataset_package_stem}'"
      ],
      "metadata": {
        "id": "fooj_BBQPbTK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка датасета с Kaggle и копирование на Google Диск (при первом запуске)\n",
        "(you'll need press button to select and upload kaggle.json from you local computer if interaction with Kaggle will be needed)"
      ],
      "metadata": {
        "id": "3ymMYZPw7ha8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if metadata file exists, if not, download and extract dataset\n",
        "metadata_path = f'{dataset_package_path}/{metadata_file}'\n",
        "if not os.path.exists(metadata_path):\n",
        "    dataset_package_zip = f\"{dataset_package_stem}.zip\"  # file name that appears to be downloaded after downloading dataset\n",
        "    dataset_package_zip_path = rf'{my_drive_dest}/{dataset_package_zip}'\n",
        "    if not os.path.exists(dataset_package_zip_path):\n",
        "        my_drive_dest_for_cmd = my_drive_dest.replace(' ', '\\ ')\n",
        "\n",
        "        # Kaggle access file (from my_drive_dest or upload)\n",
        "        if not os.path.exists(os.path.expanduser('~/.kaggle/kaggle.json')):\n",
        "            !mkdir ~/.kaggle\n",
        "            if os.path.exists(rf'{my_drive_dest}/kaggle.json'):\n",
        "                !cp $my_drive_dest_for_cmd/kaggle.json ~/.kaggle/\n",
        "            else:\n",
        "                print(\"Select kaggle.json to dounload to Google Colab\")\n",
        "                from google.colab import files\n",
        "                uploaded = files.upload()\n",
        "                !cp kaggle.json ~/.kaggle/\n",
        "            !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "        # Dataset zip file (autoskipping if exist)\n",
        "        !kaggle datasets download $dataset_package_name -p $my_drive_dest_for_cmd\n",
        "\n",
        "    import zipfile\n",
        "\n",
        "    with zipfile.ZipFile(dataset_package_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(dataset_package_path)\n",
        "\n",
        "# # Directory to extract the contents\n",
        "# extract_path = 'dataset_package_folder'\n",
        "\n",
        "# # Create the extraction directory if it doesn't exist\n",
        "# os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# # Extract the zip file\n",
        "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "AR5NVO1PtqMo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Просмотр состава данных"
      ],
      "metadata": {
        "id": "9s1g_yUt_rK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load metadata from Excel file\n",
        "df_in = pd.read_excel(metadata_path)\n",
        "df_in.set_index(\"Name\", inplace=True)\n",
        "print(df_in['# pics'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXufqegmf4o7",
        "outputId": "8773f4be-38c6-4a41-9a32-3c0d00e9e1ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name\n",
            "Alfalfa                50\n",
            "Asparagus             100\n",
            "Blue Vervain           50\n",
            "Broadleaf Plantain     50\n",
            "Bull Thistle           50\n",
            "                     ... \n",
            "Wild Bee Balm          50\n",
            "Wild Black Cherry      50\n",
            "Wild Grape Vine       100\n",
            "Wild Leek             100\n",
            "Wood Sorrel            50\n",
            "Name: # pics, Length: 62, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "custom-dataset-class"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the device to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7smZArVj54-p",
        "outputId": "fe338fc0-6219-4fdb-dcdc-0ee8aff4abfc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверка наличия изображений данных в ожидаемых директориях и отображение сетки изображений"
      ],
      "metadata": {
        "id": "weGrTFiMQy3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Check if images are available in the expected directories\n",
        "def check_images_availability(datasets_root):\n",
        "    subfolders = ['dataset', 'dataset-test', 'dataset-user_images']\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_path = os.path.join(datasets_root, subfolder)\n",
        "        if not os.path.exists(subfolder_path):\n",
        "            print(f\"Directory {subfolder_path} does not exist.\")\n",
        "            return False\n",
        "        if not os.listdir(subfolder_path):\n",
        "            print(f\"Directory {subfolder_path} is empty.\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Draw a grid of one image for each class\n",
        "def draw_image_grid(datasets_root):\n",
        "    classes = os.listdir(os.path.join(datasets_root, 'dataset'))\n",
        "    num_classes = len(classes)\n",
        "    fig, axes = plt.subplots(1, num_classes, figsize=(20, 20))\n",
        "    for i, cls in enumerate(classes):\n",
        "        class_path = os.path.join(datasets_root, 'dataset', cls)\n",
        "        image_file = random.choice(os.listdir(class_path))\n",
        "        image_path = os.path.join(class_path, image_file)\n",
        "        image = Image.open(image_path)\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(cls)\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Check images availability and draw grid\n",
        "datasets_path = f'{dataset_package_path}/datasets'\n",
        "if check_images_availability(datasets_path):\n",
        "    draw_image_grid(datasets_path)\n",
        "else:\n",
        "    print(\"Images are not available in the expected directories.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kan5_xi9Qxxw",
        "outputId": "3d2b7c44-460b-4c14-ae86-3ea641cd0e21"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory drive/My Drive/Colab Notebooks/Методы ИИ/edible-wild-plants/dataset/dataset does not exist.\n",
            "Images are not available in the expected directories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание своего класса PyTorch.Dataset для загрузки данных в PyTorch"
      ],
      "metadata": {
        "id": "oL0r66XQYTdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class DatasetE(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = glob.glob(f'{root_dir}/**/*.jpg', recursive=True)\n",
        "        self.labels = [path.split('/')[-2] for path in self.image_paths]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "custom-dataset-class-code"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Предобработка изображений"
      ],
      "metadata": {
        "id": "image-preprocessing"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import v2\n",
        "\n",
        "# Define the data transformations\n",
        "data_transforms = v2.Compose([\n",
        "    v2.RandomResizedCrop(size=(224, 224), antialias=True),  # Randomly crop and resize images to 224x224 pixels with antialiasing\n",
        "    v2.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    v2.RandomRotation(10),  # Randomly rotate images by 10 degrees\n",
        "    v2.ToImage(), v2.ToDtype(torch.float32, scale=True),  # Convert images to PyTorch tensors\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images with mean and std\n",
        "])"
      ],
      "metadata": {
        "id": "image-preprocessing-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2985cf-8af7-4e7d-bbcb-705b0b00d0a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Разделение датасета на обучающую и тестовую выборки"
      ],
      "metadata": {
        "id": "dataset-splitting"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "dataset = DatasetE(root_dir=datasets_path, transform=data_transforms)\n",
        "train_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)"
      ],
      "metadata": {
        "id": "dataset-splitting-code"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Примеры распознавания из папки dataset-user_images"
      ],
      "metadata": {
        "id": "recognition-examples"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and display examples from user images dataset\n",
        "user_images_dataset = DatasetE(root_dir=f'{datasets_path}/dataset-user_images', transform=data_transforms)\n",
        "\n",
        "for i in range(5):\n",
        "    image, label = user_images_dataset[i]\n",
        "    plt.imshow(image.permute(1, 2, 0))\n",
        "    plt.title(label)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "recognition-examples-code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "0653c366-78e7-4f9d-b48d-f0a62933600d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-23e65d0d4fae>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_images_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-d98196073dec>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}